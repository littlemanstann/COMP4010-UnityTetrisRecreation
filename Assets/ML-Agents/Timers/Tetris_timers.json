{"count":1,"self":54.1106816,"total":56.6600731,"children":{"InitializeActuators":{"count":1,"self":0.0020282,"total":0.0020282,"children":null},"InitializeSensors":{"count":1,"self":0,"total":0,"children":null},"AgentSendState":{"count":1887,"self":0.021283299999999998,"total":0.4220121,"children":{"CollectObservations":{"count":959,"self":0.3528552,"total":0.3528552,"children":null},"WriteActionMask":{"count":959,"self":0.0027458,"total":0.0027458,"children":null},"RequestDecision":{"count":959,"self":0.0093704,"total":0.045127799999999996,"children":{"AgentInfo.ToProto":{"count":959,"self":0.008692,"total":0.0357574,"children":{"GenerateSensorData":{"count":959,"self":0.0270654,"total":0.0270654,"children":null}}}}}}},"DecideAction":{"count":1887,"self":1.7723099999999998,"total":1.7723100999999999,"children":null},"AgentAct":{"count":1887,"self":0.35245699999999996,"total":0.3530384,"children":{"AgentInfo.ToProto":{"count":30,"self":0,"total":0.00058139999999999993,"children":{"GenerateSensorData":{"count":30,"self":0.00058139999999999993,"total":0.00058139999999999993,"children":null}}}}}},"gauges":{"TetrisAgent.CumulativeReward":{"count":30,"max":-7.0994997,"min":-8.9495,"runningAverage":-8.179217,"value":-7.7105,"weightedAverage":-7.886852}},"metadata":{"timer_format_version":"0.1.0","start_time_seconds":"1764614224","unity_version":"6000.2.13f1","command_line_arguments":"C:\\Program Files\\Unity\\Hub\\Editor\\6000.2.13f1\\Editor\\Unity.exe -projectpath C:\\Users\\hstan\\OneDrive\\Documents\\! Uni Year 4\\COMP 4010 A (Intro to Reinforcement Learning)\\COMP4010-UnityTetrisRecreation -acceptSoftwareTermsForThisRunOnly -useHub -hubIPC -cloudEnvironment production","communication_protocol_version":"1.5.0","com.unity.ml-agents_version":"4.0.0","scene_name":"Tetris","end_time_seconds":"1764614281"}}